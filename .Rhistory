install.packages("mgcv")
install.packages("ggplot2")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
load("~/Downloads/goalie_stats_2017-11-05.csv")
goalie_stats_2017.11.05 <- read.csv("~/Downloads/goalie_stats_2017-11-05.csv")
View(goalie_stats_2017.11.05)
goalie_stats_2017.11.05
library("rlang", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
detach("package:rlang", unload=TRUE)
install.packages("nflscrapr")
install.packages("nflscrapr")
install.packages("nflscrapr")
install.packages("tidyverse")
install.packages("devtools")
install.packages("nflscrapr")
install.packages("nflscrapR")
devtools::install_github(repo = "maksimhorowitz/nflscrapR")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
library(nflscrapR)
library(tidyverse)
pbp_data <- scrape_json_play_by_play(2018091700)
source('~/.active-rstudio-document', echo=TRUE)
pbp_data <- scrape_season_play_by_play(2018091700)
write.csv(pbp_data, file = "season2018.csv",row.names=FALSE)
pbp_data <- scrape_season_play_by_play(2018091700)
write.csv(pbp_data, file = "season2018.csv",row.names=FALSE)
pbp_data <- scrape_season_play_by_play(2018092000)
write.csv(pbp_data, file = "season2018.csv",row.names=FALSE)
scrape_game_play_by_play <- function(game_id, type, season, check_url = 1) {
# First check that the type is one of the required options:
assertthat::assert_that(tolower(type) %in% c("reg", "pre", "post"),
msg = "Input for type is not valid! Should either be 'reg', 'pre', or 'post'.")
# Next check that if the type is pre then the season is at least 1999:
if (tolower(type) == "pre") {
assertthat::assert_that(as.numeric(season) >= 2000,
msg = "Preseason game ids with data are only available starting in 2000!")
# Otherwise check to see that it's at least 1998
} else {
assertthat::assert_that(as.numeric(season) >= 1998,
msg = "Regular and post-season game ids with data are only available starting in 1998!")
}
# Scrape JSON data for games since 2009, HTML for everything prior to that:
if (season >= 2009) {
game_pbp <- scrape_json_play_by_play(game_id, check_url)
} else {
# game_pbp <- scrape_html_play_by_play(game_id, check_url)
# This will be added later:
print("Game data prior to 2009 coming soon!")
game_pbp <- NA
}
# Return the game's data:
return(game_pbp)
}
library("nflscrapR", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
scrape_game_play_by_play <- function(game_id, type, season, check_url = 1) {
# First check that the type is one of the required options:
assertthat::assert_that(tolower(type) %in% c("reg", "pre", "post"),
msg = "Input for type is not valid! Should either be 'reg', 'pre', or 'post'.")
# Next check that if the type is pre then the season is at least 1999:
if (tolower(type) == "pre") {
assertthat::assert_that(as.numeric(season) >= 2000,
msg = "Preseason game ids with data are only available starting in 2000!")
# Otherwise check to see that it's at least 1998
} else {
assertthat::assert_that(as.numeric(season) >= 1998,
msg = "Regular and post-season game ids with data are only available starting in 1998!")
}
# Scrape JSON data for games since 2009, HTML for everything prior to that:
if (season >= 2009) {
game_pbp <- scrape_json_play_by_play(game_id, check_url)
} else {
# game_pbp <- scrape_html_play_by_play(game_id, check_url)
# This will be added later:
print("Game data prior to 2009 coming soon!")
game_pbp <- NA
}
# Return the game's data:
return(game_pbp)
}
pbp_data <- scrape_season_play_by_play(2018092000)
write.csv(pbp_data, file = "season2018.csv",row.names=FALSE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
pbp_data <- scrape_season_play_by_play(2018)
pbp_18 <- read_csv("https://raw.githubusercontent.com/ryurko/nflscrapR-data/master/play_by_play_data/regular_season/reg_pbp_2018.csv")
View(pbp_18)
View(pbp_18)
View(pbp_18)
library(readr)
season2018 <- read_csv("Downloads/nfl/season2018.csv")
View(season2018)
View(scrape_game_play_by_play)
install.packages(c("backports", "BH", "broom", "callr", "class", "clipr", "codetools", "colorspace", "curl", "dbplyr", "dplyr", "DT", "foreign", "git2r", "haven", "httpuv", "httr", "jsonlite", "knitr", "lattice", "markdown", "MASS", "Matrix", "mgcv", "openssl", "pillar", "processx", "ps", "rcmdcheck", "Rcpp", "readr", "readxl", "RJSONIO", "rlang", "rmarkdown", "rstudioapi", "sessioninfo", "shiny", "survival", "tibble", "tinytex"))
setwd("~/Documents/dev/football")
library(nflscrapR)
library(tidyverse)
library(readr)
library(pander)
library(dplyr)
library(na.tools)
library(ggimage)
userYear <- 2019
g <- read.csv(paste("data/games_data/reg_season/reg_games_2019")
g <- read.csv(paste("data/games_data/reg_season/reg_games_2019.csv")
g <- read.csv(paste("data/games_data/reg_season/reg_games_2019.csv"))
g <- g %>% filter(state_of_game == "POST")
View(g)
g <- g %>% pull(game_id)
View(g)
g <- read.csv(paste("data/games_data/reg_season/reg_games_", userYear, ".csv", sep = ""))
g <- g %>% filter(state_of_game == "POST")
id <- g %>% pull(game_id)
new_plays <- NULL
for (x in id) {
game_plays <- read.csv(paste("data/games_data/", userYear, "/", x, sep = ""))
new_plays <- bind_rows(new_plays,game_plays)
}
write.csv(new_plays, "pbp2019.csv")
for (x in id) {
game_plays <- read.csv(paste("data/games_data/", userYear, "/", x, ".csv", sep = ""))
new_plays <- bind_rows(new_plays,game_plays)
}
write.csv(new_plays, "pbp2019.csv")
paste("data/games_data/", userYear, "pbp", userYear, ".csv", sep = "")
paste("data/games_data/", userYear, "/pbp", userYear, ".csv", sep = "")
new_plays <- NULL
for (x in id) {
game_plays <- read.csv(paste("data/games_data/", userYear, "/", x, ".csv", sep = ""))
new_plays <- bind_rows(new_plays,game_plays)
}
write.csv(new_plays, paste("data/games_data/", userYear, "/pbp", userYear, ".csv", sep = ""))
warnings()
pull(g$game_id)
source('~/.active-rstudio-document')
