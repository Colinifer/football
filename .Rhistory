install.packages("mgcv")
install.packages("ggplot2")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
load("~/Downloads/goalie_stats_2017-11-05.csv")
goalie_stats_2017.11.05 <- read.csv("~/Downloads/goalie_stats_2017-11-05.csv")
View(goalie_stats_2017.11.05)
goalie_stats_2017.11.05
library("rlang", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
detach("package:rlang", unload=TRUE)
install.packages("nflscrapr")
install.packages("nflscrapr")
install.packages("nflscrapr")
install.packages("tidyverse")
install.packages("devtools")
install.packages("nflscrapr")
install.packages("nflscrapR")
devtools::install_github(repo = "maksimhorowitz/nflscrapR")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
library(nflscrapR)
library(tidyverse)
pbp_data <- scrape_json_play_by_play(2018091700)
source('~/.active-rstudio-document', echo=TRUE)
pbp_data <- scrape_season_play_by_play(2018091700)
write.csv(pbp_data, file = "season2018.csv",row.names=FALSE)
pbp_data <- scrape_season_play_by_play(2018091700)
write.csv(pbp_data, file = "season2018.csv",row.names=FALSE)
pbp_data <- scrape_season_play_by_play(2018092000)
write.csv(pbp_data, file = "season2018.csv",row.names=FALSE)
scrape_game_play_by_play <- function(game_id, type, season, check_url = 1) {
# First check that the type is one of the required options:
assertthat::assert_that(tolower(type) %in% c("reg", "pre", "post"),
msg = "Input for type is not valid! Should either be 'reg', 'pre', or 'post'.")
# Next check that if the type is pre then the season is at least 1999:
if (tolower(type) == "pre") {
assertthat::assert_that(as.numeric(season) >= 2000,
msg = "Preseason game ids with data are only available starting in 2000!")
# Otherwise check to see that it's at least 1998
} else {
assertthat::assert_that(as.numeric(season) >= 1998,
msg = "Regular and post-season game ids with data are only available starting in 1998!")
}
# Scrape JSON data for games since 2009, HTML for everything prior to that:
if (season >= 2009) {
game_pbp <- scrape_json_play_by_play(game_id, check_url)
} else {
# game_pbp <- scrape_html_play_by_play(game_id, check_url)
# This will be added later:
print("Game data prior to 2009 coming soon!")
game_pbp <- NA
}
# Return the game's data:
return(game_pbp)
}
library("nflscrapR", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
scrape_game_play_by_play <- function(game_id, type, season, check_url = 1) {
# First check that the type is one of the required options:
assertthat::assert_that(tolower(type) %in% c("reg", "pre", "post"),
msg = "Input for type is not valid! Should either be 'reg', 'pre', or 'post'.")
# Next check that if the type is pre then the season is at least 1999:
if (tolower(type) == "pre") {
assertthat::assert_that(as.numeric(season) >= 2000,
msg = "Preseason game ids with data are only available starting in 2000!")
# Otherwise check to see that it's at least 1998
} else {
assertthat::assert_that(as.numeric(season) >= 1998,
msg = "Regular and post-season game ids with data are only available starting in 1998!")
}
# Scrape JSON data for games since 2009, HTML for everything prior to that:
if (season >= 2009) {
game_pbp <- scrape_json_play_by_play(game_id, check_url)
} else {
# game_pbp <- scrape_html_play_by_play(game_id, check_url)
# This will be added later:
print("Game data prior to 2009 coming soon!")
game_pbp <- NA
}
# Return the game's data:
return(game_pbp)
}
pbp_data <- scrape_season_play_by_play(2018092000)
write.csv(pbp_data, file = "season2018.csv",row.names=FALSE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
pbp_data <- scrape_season_play_by_play(2018)
pbp_18 <- read_csv("https://raw.githubusercontent.com/ryurko/nflscrapR-data/master/play_by_play_data/regular_season/reg_pbp_2018.csv")
View(pbp_18)
View(pbp_18)
View(pbp_18)
library(readr)
season2018 <- read_csv("Downloads/nfl/season2018.csv")
View(season2018)
View(scrape_game_play_by_play)
install.packages(c("backports", "BH", "broom", "callr", "class", "clipr", "codetools", "colorspace", "curl", "dbplyr", "dplyr", "DT", "foreign", "git2r", "haven", "httpuv", "httr", "jsonlite", "knitr", "lattice", "markdown", "MASS", "Matrix", "mgcv", "openssl", "pillar", "processx", "ps", "rcmdcheck", "Rcpp", "readr", "readxl", "RJSONIO", "rlang", "rmarkdown", "rstudioapi", "sessioninfo", "shiny", "survival", "tibble", "tinytex"))
##install.packages("devtools", "tidyverse", "readr", "pander", "na.tools", "ggimage", "devtools", "teamcolors")
##devtools::install_github(repo = "maksimhorowitz/nflscrapR")
library(nflscrapR)
library(tidyverse)
library(readr)
library(pander)
library(dplyr)
library(na.tools)
library(ggimage)
library(teamcolors)
##reset
setwd("~/")
gid <- paste(getwd())
gid
device <- ""
if (gid == "/Volumes/HDD/Users/colinwelsh") {
##Maverick - MBP
setwd("~/Documents/dev/football")
device <- "Maverick (MBP)"
} else if (gid == "/Users/ColinWelsh") {
##Goose - iMac
setwd("~/Documents/dev/football")
device <- "Goose (iMac)"
##add Goose
}
print(paste(device, "is ready for some football", sep = " "))
rm(gid, device)
# set custom variables
userYear <- 2019 ##necessary for saved
userWeek <- 5 ##not necessary at the moment
today <- Sys.Date()
# test date
date <- 201910
#date <- format(today, format="%Y%m%d")
game_ids <- read.csv("data/games_data/reg_season/reg_games_2019.csv", check.names = FALSE)
currentGameIDs <- game_ids$game_id
#pull games in 2019 season that match today's date
currentGames <- grep(date, currentGameIDs)
games_in_play <- currentGameIDs[currentGames]
##can't figure this out yet
#
#  games_in_play <- game_ids$state_of_game[currentGames] != "POST"
#
#  nplay <- length(games_in_play)
#  nplayLoop <- 1
#
# scrape pbp of active games
# if 0 games, scrape scores
for (x in games_in_play) {
f <- paste("data/games_data/", userYear, "/", x, ".csv", sep = "")
if (file.exists(f)==TRUE) {
#read game csv
y <- read.csv(f, check.names=FALSE)
#check if y$desc contains "END GAME"
#if x has END GAME change state_of_game to POST
if(grepl("END GAME", y$desc[nrow(y)]) == TRUE) {
print(paste("Game", x, "is over.", sep = " "))
} else {
#scrape
print(paste("Scraping game ", x, sep = ""))
y <- scrape_json_play_by_play(x)
game_ids$X <- NULL ## annoying glitch
if(grepl("END GAME", y$desc[nrow(y)]) == TRUE) {
print(paste("Game", x, "is over.", sep = " "))
game_ids[game_ids$game_id == x, "state_of_game"] <- "POST"
print(paste("Changing the state of game for ", x, " to POST", sep = ""))
write.csv(game_ids, "data/games_data/reg_season/reg_games_2019.csv", row.names=FALSE)
}
write.csv(y, file = paste("data/games_data/", userYear,"/", x, ".csv", sep = ""), row.names=FALSE)
print(paste("Last play:", y$desc[nrow(y)], sep=""))
}
}
else {
print(paste("Scraping game", x, sep = " "))
y <- scrape_json_play_by_play(x)
write.csv(y, file = paste("data/games_data/", userYear,"/", x, ".csv", sep = ""), row.names=FALSE)
}
}
## graph new scrape
homeTeam_abbr <- game_ids[game_ids$game_id == x, "home_team"]
awayTeam_abbr <- game_ids[game_ids$game_id == x, "away_team"]
homeTeam_abbr <- y$home_team[1]
awayTeam_abbr <- y$away_team[1]
teamAbbr <- read.csv(paste("data/games_data/", userYear, "/team_abbr.csv", sep = ""))
homeTeamInt <- grep(homeTeam_abbr, teamAbbr$nflscrapr_abbrev)
awayTeamInt <- grep(awayTeam_abbr, teamAbbr$nflscrapr_abbrev)
# awayTeamInt <- 24 # if Rams
homeTeam_fullname <- teamAbbr$full_name[homeTeamInt]
awayTeam_fullname <- teamAbbr$full_name[awayTeamInt]
homeTeam_logo <- nfl_teamcolors$logo[homeTeamInt]
awayTeam_logo <- nfl_teamcolors$logo[awayTeamInt]
# note: home/awayTeam currently grabs abbrev name, need to get full name.
# note: Pull out the Home and Away colors:
# note: Make this dynamic across games and add to loop
nfl_teamcolors <- teamcolors %>% filter(league == "nfl")
awayTeam_color <- nfl_teamcolors %>%
filter(name == awayTeam_fullname) %>%
pull(primary)
homeTeam_color <- nfl_teamcolors %>%
filter(name == homeTeam_fullname) %>%
pull(primary)
# Now generate the win probability chart:
y %>%
filter(!is.na(away_wp),
!is.na(home_wp)) %>%
dplyr::select(game_seconds_remaining,
away_wp,
home_wp) %>%
gather(team, wpa, -game_seconds_remaining) %>%
ggplot(aes(x = game_seconds_remaining, y = wpa, color = team)) +
geom_line(size = 2) +
geom_hline(yintercept = 0.5, color = "gray", linetype = "dashed") +
scale_color_manual(labels = c(awayTeam_abbr, homeTeam_abbr),
values = c(awayTeam_color, homeTeam_color),
guide = FALSE) +
scale_x_reverse(breaks = seq(0, 3600, 300)) +
annotate("text", x = 3000, y = .75, label = awayTeam_abbr, color = awayTeam_color, size = 8) +
annotate("text", x = 3000, y = .25, label = homeTeam_abbr, color = homeTeam_color, size = 8) +
geom_vline(xintercept = 900, linetype = "dashed", black) +
geom_vline(xintercept = 1800, linetype = "dashed", black) +
geom_vline(xintercept = 2700, linetype = "dashed", black) +
geom_vline(xintercept = 0, linetype = "dashed", black) +
labs(
x = "Time Remaining (seconds)",
y = "Win Probability",
title = paste("Week", userWeek, "Win Probability Chart", sep = " "),
subtitle = paste(awayTeam_fullname, "vs.", homeTeam_fullname, sep = " "),
caption = "Data from nflscrapR"
) + theme_bw()
##  game_ids[game_ids$game_id == 2019093000, "state_of_game"] <- "PRE"
##  write.csv(game_ids, "data/games_data/reg_season/reg_games_2019.csv")
##print the last 3 plays
## note: class/function this somehow??
print("Last play:")
print(paste("EPA Added:", y$epa[nrow(y)-2], ",", y$desc[nrow(y)-2], sep = " "))
print(paste("EPA Added:", y$epa[nrow(y)-1], ",", y$desc[nrow(y)-1], sep = " "))
print(paste("EPA Added:", y$epa[nrow(y)], ",", y$desc[nrow(y)], sep = " "))
print(paste(awayTeam_fullname, "Win Probability:", y$away_wp[nrow(y)], sep=" "))
print(paste(homeTeam_fullname, "Win Probability:", y$home_wp[nrow(y)], sep = " "))
## note: print winner and score
##  endGame == TRUE
sum(y$penalty_yards[!is.na(y$penalty_yards)] & y$penalty_team == "DAL")
y$penalty_team=="DAL"[penalty_yards[!is.na(y$penalty_yards)]]
game_ids[game_ids$game_id == x, "state_of_game"]
x
